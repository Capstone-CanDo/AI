import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import os
import joblib


df_mal = pd.read_csv("data/baseline/pre-train/phishing_output.csv", index_col=0)   # ì•…ì„±ë§Œ
df_ben = pd.read_csv("data/baseline/pre-train/normal_1000_preprocessed.csv", index_col=0)      # ì •ìƒë§Œ

#ë¼ë²¨, ì•…ì„± 1, ì •ìƒ 0
df_mal['target'] = 1
df_ben['target'] = 0

df = pd.concat([df_mal, df_ben], ignore_index=True)
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

drop_cols = ["url"]

X = df.drop(columns=drop_cols + ["target"])
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.3, random_state=42
)

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ 
model = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    n_jobs=-1,
    random_state=42
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\n Classification Report:")
print(classification_report(y_test, y_pred))


# Feature Importance ì¶œë ¥

importances = model.feature_importances_
feature_names = X.columns

print("\n Feature Importances:")
for name, score in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):
    print(f"{name:20} : {score:.4f}")


# ëª¨ë¸ ìë™ ì €ì¥ 
os.makedirs("models", exist_ok=True)   # í´ë” ì—†ìœ¼ë©´ ìƒì„±
save_path = "models/baseline.pkl"

joblib.dump(model, save_path)

print(f"\nğŸ‰ ëª¨ë¸ ì €ì¥ ì™„ë£Œ â†’ {save_path}")
